{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Gaffer with PySpark and GraphFrames #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gafferpy_pyspark import gafferpy_pyspark_session as gs\n",
    "from gafferpy_core import gaffer as g\n",
    "from gafferpy_core import gaffer_utils as u\n",
    "from gafferpy_pyspark import gaffer_pyspark as gp\n",
    "\n",
    "from graphframes import *\n",
    "import os\n",
    "import math\n",
    "from matplotlib import pyplot as plot\n",
    "\n",
    "from pyspark.sql.functions import asc,desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a Gaffer PySpark session and do some setup ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.GafferPysparkSession().create_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = u.User(user_id=\"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gaffer_home = os.environ[\"GAFFER_HOME\"]\n",
    "print(gaffer_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemaPath = gaffer_home + \"/example/schema.json\"\n",
    "graphConfigPath = gaffer_home + \"/example/graphconfig.json\"\n",
    "storePropertiesPath = gaffer_home + \"/miniaccumulo/pyspark.store.properties\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a connection to the graph ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = (gs.Graph.Builder()\n",
    "         .schema(schemaPath)\n",
    "         .config(graphConfigPath)\n",
    "         .storeProperties(storePropertiesPath)\n",
    "         .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(graph.getSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add some data using Spark ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_op = gp.CalculateSplitPointsQuickstart(\n",
    "    dataPath=gaffer_home + \"/example/data.csv\",\n",
    "    elementGeneratorConfig=gaffer_home + \"/example/element-generator.json\",\n",
    "    splitsFilePath=gaffer_home + \"/splitsFile\",\n",
    "    numSplits=5,\n",
    "    sampleRatioForSplits=\"0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execute(split_op,user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_op = gp.AddElementsFromHdfsQuickstart(\n",
    "    dataPath=gaffer_home + \"/example/data.csv\", \n",
    "    elementGeneratorConfig=gaffer_home + \"/example/element-generator.json\",\n",
    "    splitsFilePath=gaffer_home + \"/splitsFile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph.execute(add_op, user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a simple query ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_def = g.ElementDefinition(group=\"Emitter\", group_by=[])\n",
    "edge_def = g.ElementDefinition(group=\"Event\", group_by=[])\n",
    "entity_view = g.View(entities=[entity_def])\n",
    "edges_view = g.View(edges=[edge_def])\n",
    "view = g.View(entities=[entity_def], edges=[edge_def])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_op = g.GetElements(input=[g.EntitySeed(\"1\")], view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = graph.execute(get_op, user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for element in results:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the degree distribution ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_rdd_op = gp.GetPySparkRDDOfAllElements(view=entity_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_rdd = graph.execute(entities_rdd_op, user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countInDegree(entity):\n",
    "    return (entity.properties.get(\"messagesReceivedEstimate\"), 1)\n",
    "\n",
    "def countOutDegree(entity):\n",
    "    return (entity.properties.get(\"messagesSentEstimate\"), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_distro_rdd = entities_rdd.map(countInDegree).reduceByKey(lambda a, b: a + b)\n",
    "out_distro_rdd = entities_rdd.map(countInDegree).reduceByKey(lambda a, b: a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_distro = in_distro_rdd.collect()\n",
    "out_distro = out_distro_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "in_x = []\n",
    "in_y = []\n",
    "in_log_x = []\n",
    "in_log_y = []\n",
    "for in_entry in in_distro:\n",
    "    in_x.append(in_entry[0])\n",
    "    in_y.append(in_entry[1])\n",
    "    if in_entry[0] != 0:\n",
    "        in_log_x.append(math.log(in_entry[0]))\n",
    "        in_log_y.append(math.log(in_entry[1]))\n",
    "\n",
    "out_x = []\n",
    "out_y = []\n",
    "out_log_x = []\n",
    "out_log_y = []\n",
    "for out_entry in out_distro:\n",
    "    out_x.append(out_entry[0])\n",
    "    out_y.append(out_entry[1])\n",
    "    if out_entry[0] != 0:\n",
    "        out_log_x.append(math.log(out_entry[0]))\n",
    "        out_log_y.append(math.log(out_entry[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [16, 8]\n",
    "plt.rcParams['axes.labelsize'] = 'x-large'\n",
    "plt.rcParams['legend.fontsize'] = 'x-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(in_x, in_y, c='b', marker='x', label='in_degree')\n",
    "plt.scatter(out_x, out_y, c='r', marker='o', label='out_degree')\n",
    "plt.xlabel(\"count\")\n",
    "plt.ylabel(\"degree\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(in_log_x, in_log_y, c='b', marker='x', label='in_degree')\n",
    "plt.scatter(out_log_x, out_log_y, c='r', marker='o', label='out_degree')\n",
    "plt.xlabel(\"log(count)\")\n",
    "plt.ylabel(\"log(degree)\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a GraphFrame ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitter_def = g.ElementDefinition(group=\"Emitter\", group_by=[])\n",
    "event_def = g.ElementDefinition(group=\"Event\", group_by=[])\n",
    "\n",
    "emitter_view = g.View(entities=[emitter_def])\n",
    "event_view = g.View(edges=[event_def])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitter_df_op = gp.GetPysparkDataFrameOfElements(view=emitter_view)\n",
    "event_df_op = gp.GetPysparkDataFrameOfElements(view=event_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitter_df = graph.execute(emitter_df_op, user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitter_df.sort(desc(\"count\")).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = graph.execute(event_df_op, user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df.sort(desc(\"count\")).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphframe = GraphFrame(\n",
    "    emitter_df.select(\"vertex\").withColumnRenamed(\"vertex\", \"id\"),\n",
    "    event_df.select(\"source\", \"destination\").withColumnRenamed(\"source\", \"src\").withColumnRenamed(\"destination\", \"dst\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Pageranks for the `Emitter` vertices ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitter_pagerank_gf = graphframe.pageRank(resetProbability=0.15, maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitter_pageranks = emitter_pagerank_gf.vertices.select('id', 'pagerank').sort(desc('pagerank'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "emitter_pageranks.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the Pageranks back into the graph as entities ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toPagerankToEntity(vertex,pagerank):\n",
    "    entity = g.Entity(\n",
    "        vertex=vertex, \n",
    "        group=\"Pagerank\", \n",
    "        properties={\n",
    "            \"pagerank\" : pagerank\n",
    "        })\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitter_pr_rdd = emitter_pageranks.sort('id').rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitter_pr_elements = emitter_pr_rdd.map(lambda x : toPagerankToEntity(x['id'], x['pagerank']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitter_import_pr_op = gp.AddElementsFromPysparkRDD(rdd=emitter_pr_elements, outputDirectory=gaffer_home + \"/import/pr/emitter/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph.execute(emitter_import_pr_op, user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_def = g.ElementDefinition(group=\"Pagerank\")\n",
    "pr_view = g.View(entities=[pr_def])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pr_op = g.GetElements(input=[g.EntitySeed(\"1\")], view=pr_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = graph.execute(get_pr_op, user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in pr:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use LPA to divide the Emitters into communities ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitters_lpa = graphframe.labelPropagation(maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countValues(val):\n",
    "    return (val[\"label\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitters_lpa_labels = emitters_lpa.select(\"label\").rdd.map(countValues).reduceByKey(lambda a,b : a+b).toDF([\"label\", \"count\"]).sort(desc(\"count\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitters_lpa_labels.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community = emitters_lpa.select('id').filter('label = 247').toPandas()['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emitter in community:\n",
    "    print(emitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the communities back into the graph as entities ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toLpaToEntity(vertex,community):\n",
    "    entity = g.Entity(\n",
    "        vertex=vertex, \n",
    "        group=\"Community\", \n",
    "        properties={\n",
    "            \"community\" : str(community)\n",
    "        })\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitters_lpa_rdd = emitters_lpa.select(\"id\", \"label\").sort(\"id\").rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitter_lpa_elements = emitters_lpa_rdd.map(lambda x : toLpaToEntity(x[\"id\"], x[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitters_import_lpa_op = gp.AddElementsFromPysparkRDD(rdd=emitter_lpa_elements, outputDirectory=gaffer_home + \"/import/lpa/emitter/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execute(emitters_import_lpa_op, user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_def = g.ElementDefinition(group=\"Community\")\n",
    "community_view = g.View(entities=[community_def])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_community_op = g.GetElements(input=[g.EntitySeed(\"1902\")], view=community_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = graph.execute(get_community_op, user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in communities:\n",
    "    print(entity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
